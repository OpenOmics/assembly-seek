# Python standard library
from os.path import join
from os import listdir
import os, sys, re, json

# 3rd party imports from pypi
from snakemake.io import expand

# Local imports
from scripts.common import (
    allocated,
    provided,
    references,
    str_bool,
    identify_samples_as_bam_fastq
)


# Global workflow variables
configfile: 'config.json'
SAMPLE          = config["samples"]                      # List: Base name of input samples
ASSEMBLER       = config["options"]["assemblers"]        # List: Assemblers to use, default: ["flye", "raven", "hifiasm"]
workpath        = config["project"]["workpath"]          # Pipeline's output directory
Genome_size     = config["options"]["genome_size"]       # Estimated genome size for Flye assembler
busco_links     = config["busco_links"]                  # Dict: Lineage to busco download link mappings
Lineage_name    = config["options"]["lineage_name"]      # Busco linage name
odb10_refs_path = config["odb10_refs_path"]              # Base path to locally downloaded Busco lineages
filetype        = config['efiletype']                    # File type of all samples
ext             = config['extensions']                   # Dict: Sample to filetype mappings, where: gz=fastq.gz, bam=bam
tmpdir          = config['options']['tmp_dir']           # Temporary directory, default: /lscratch/$SLURM_JOBID

# Flye coverage option to reduce memory 
# usage of initial disjointig assembly 
Coverage = "" if config["options"]["coverage"] == "None" \
else int(config["options"]["coverage"])

# Local path to Busco lineage database
Lineage_path = join(odb10_refs_path, Lineage_name) if Lineage_name else ""
busco_link = ""  # Busco lineage download link
if not os.access(Lineage_path, os.R_OK) and Lineage_name:
    # Busco lineage database does not
    # exist locally or it cannot be 
    # accessed due to bad permissions
    try:
        # Check if download link available
        busco_link = busco_links[Lineage_name]
    except KeyError:
        # We don't have a download URL for
        # this specific lineage, could be 
        # due to Busco updating the lineages
        # on their side and our internal index
        # is out of date or the user provided
        # something that does not exist. 
        sys.exit(
            "Fatal Error: Unsupported {0} database, please use one of the following databases:\n".format(Lineage_name),
            "https://busco-archive.ezlab.org/data/lineages/\n",
            "If this database does exist, our index maybe out of date! Please contact a maintainer of the pipeline."
        )

# Read in resource information,
# containing information about 
# threads, mem, walltimes, etc.
# TODO: Add handler for when the
# mode is set to local.
with open(join('config', 'cluster.json')) as fh:
    cluster = json.load(fh)


# Targets of the PacBio de novo assembly pipeline
rule all:
    input:
        # Converting BAM files to FastQ/FASTA format
        expand(
            join(workpath,"reads", "{samples}.fastq.gz"), samples = identify_samples_as_bam_fastq(SAMPLE, ext)[0]
        ),
        expand(
            join(workpath,"reads", "{samples}.fasta"), samples=SAMPLE
        ),
        # FastQC, assess sequencing quality
        expand(
            join(workpath, "{samples}_fastqc.html"), samples = identify_samples_as_bam_fastq(SAMPLE, ext)[1]
        ),
        # De novo genome assemblies: "flye", "raven", "hifiasm".
        expand(
            join(workpath,"{assemblers}_assembly/{samples}.{assemblers}.fasta"), 
            samples=SAMPLE, 
            assemblers=ASSEMBLER
        ),
        # Gather and reformat assemblies
        expand(
            join(workpath,"all-assemblies/{samples}.{assemblers}.fasta"),
            samples=SAMPLE,
            assemblers=ASSEMBLER
        ),
        # Quast, assess quality of assemblies
        join(workpath,"sample-quast/report.html"),
        # Busco, assess completeness and quality of assemblies
        expand(
            join(workpath,"stats_busco","{samples}.{assemblers}","short_summary.specific." + Lineage_name + ".{samples}.{assemblers}.txt"),
            samples = SAMPLE,
            assemblers=ASSEMBLER,
            Lineage_name=Lineage_name
        ),
        join(workpath,"busco-summaries/busco_figure.png")
    output:
        "multiqc_report.html"
    params:
        rname="denovoAsm"
    threads: int(allocated("threads", "all", cluster)),
    shell:
        """
        module load multiqc
        multiqc .
        """


rule bam2fastq:
    input:
        bam   = join(workpath, "{samples}.bam"),
    output:
        fastq = join(workpath, "reads", "{samples}.fastq.gz"),
    params:
        rname    = "bam2fastq",
        samtools = "samtools/1.9",
    threads: int(allocated("threads", "bam2fastq", cluster)),
    shell:
        """
        module load {params.samtools}
        # Convert BAM to FastQ format
        samtools fastq {input.bam} \\
            | gzip - \\
        > {output.fastq};
        """


rule fastq2fasta:
    input:
        fastq = lambda w: join(workpath, "reads", w.samples+".fastq.gz") if ext[w.samples]=="bam" \
        else \
        join(workpath, w.samples+".fastq.gz"),
    output:
        fasta = join(workpath, "reads", "{samples}.fasta"),
    params:
        rname="fq2fa",
        seqkit="seqkit/2.2.0",
    threads: int(allocated("threads", "fastq2fasta", cluster)),
    shell:
        """
        module load {params.seqkit}
        # Convert FastQ to FASTA format,
        # outputs a file with no line wrap
        seqkit fq2fa \\
            --line-width 0 \\
            {input.fastq} \\
            -o {output.fasta}
        """


rule QualityCheck:
    input:
        CCS=join(workpath, "{samples}.fastq.gz"),
    output:
        PBqc=join(workpath, "{samples}_fastqc.html"),
    params:
        rname="fastQC",
        tmpdir=tmpdir,
    threads: int(allocated("threads", "QualityCheck", cluster)),
    shell:
        """
        # Setups temporary directory for
        # intermediate files with built-in 
        # mechanism for deletion on exit
        if [ ! -d "{params.tmpdir}" ]; then mkdir -p "{params.tmpdir}"; fi
        tmp=$(mktemp -d -p "{params.tmpdir}")
        trap 'rm -rf "${{tmp}}"' EXIT

        # Running fastqc with local
        # disk or a tmpdir, fastqc
        # has been observed to lock
        # up gpfs filesystems, adding
        # this on request by HPC staff
        module load python/3.7 fastqc samtools
        fastqc \\
            --threads {threads} \\
            {input.CCS} \\
            -o "${{tmp}}"
        
        # Copy output files from tmpdir
        # to output directory
        find "${{tmp}}" \\
            -type f \\
            \\( -name '*.html' -o -name '*.zip' \\) \\
            -exec cp {{}} {workpath} \\;
        """    


rule raven_assembly:
    input:
        join(workpath,"reads/{samples}.fasta")
    output:
        gfa=join(workpath, "raven_assembly/{samples}.raven.gfa"),
        fa=join(workpath, "raven_assembly/{samples}.raven.fasta")
    params:
        rname="raven_assembly",
        dir=directory(join(workpath, "raven_assembly")),
        gfa="{samples}.raven.gfa",
    container: config['images']['raven'],
    threads: int(allocated("threads", "raven_assembly", cluster)),
    shell:
        """
        mkdir -p {params.dir}
        cd {params.dir}
        raven \\
            --graphical-fragment-assembly {params.gfa} \\
            --threads {threads} \\
            {input}
        awk '$1 ~/S/ {{print ">"$2"\\n"$3}}' \\
            {output.gfa} \\
        > {output.fa}
        """

# rule wtdbg2_assembly:
#     input:
#         join(workpath,"reads/{samples}.fasta")
#     output:
#         lay=join(workpath,"wtdbg2_assembly/{samples}.wtdbg2.ctg.lay.gz"),
#         fa=join(workpath,"wtdbg2_assembly/{samples}.wtdbg2.ctg.fa")
#     params:
#         rname="wtdbg2_assembly",
#         dir=directory(join(workpath,"wtdbg2_assembly")),
#         tag="{samples}.wtdbg2"
#     threads: 32
#     #conda: "envs/wtdbg2.yaml"
#     shell:
#         """
#         source /data/NCBR/apps/genome-assembly/conda/etc/profile.d/conda.sh
#         conda activate wtdbg2
#         mkdir -p {params.dir}
#         cd {params.dir}
#         wtdbg2 -x sq -g {Genome_size} -t {threads} -i {input} -f -o {params.tag}
#         wtpoa-cns -t {threads} -i {output.lay} -fo {output.fa}
#         conda deactivate
#         """

# rule minipolish_assembly:
#     input:
#         fastq_file = lambda w: join(workpath,"reads/{w.samples}.fastq") \
#         if ext[w.samples]=="bam" else join(rawdata_dir, "{samples}.fastq")
#     output:
#         ovlp=join(workpath,"minipolish_assembly/{samples}.minimap2-overlaps.paf"),
#         gfa1=join(workpath,"minipolish_assembly/{samples}.miniasm-assembly.gfa"),
#         gfa2=join(workpath,"minipolish_assembly/{samples}.minipolished-assembly.gfa"),
#         fa=join(workpath,"minipolish_assembly/{samples}.minipolished-assembly.fa")
#     params:
#         rname="minipolish_assembly",
#         dir=directory(join(workpath,"minipolish_assembly"))
#     #conda: "envs/minipolish.yaml"
#     threads: 32
#     shell:
#         """
#         source /data/NCBR/apps/genome-assembly/conda/etc/profile.d/conda.sh
#         conda activate minipolish
#         mkdir -p {params.dir}
#         module load miniasm/0.3.r179
#         minimap2 -t {threads} -x ava-pb {input} {input} > {output.ovlp}
#         miniasm -f {input} {output.ovlp} > {output.gfa1}
#         minipolish --threads {threads} {input} {output.gfa1} > {output.gfa2}
#         awk '$1 ~/S/ {{print ">"$2"\\n"$3}}' {output.gfa2} > {output.fa}
#         conda deactivate
#         """

rule flye_assembly:
    input:
        file = lambda w: join(workpath,"reads", w.samples+".fasta") \
        if ext[w.samples]=="bam" else join(workpath, w.samples+".fastq.gz")
    output:
        join(workpath,"flye_assembly/{samples}.flye.fasta")
    params:
        rname="flye_assembly",
        flye="flye/2.9.1",
        id="{samples}",
        dir= join(workpath,"flye_assembly"),
        genome_size_flag= "--genome-size" if Genome_size != "" else "",
        asm_coverage_flag= "--asm-coverage" if Coverage != "" else ""
    threads: int(allocated("threads", "flye_assembly", cluster)),
    shell:
        """
        module load {params.flye}
        mkdir -p {params.rname}
        cd /lscratch/$SLURM_JOBID
        mkdir -p {params.rname}/{params.id}
        flye \\
            --threads {threads} \\
            --pacbio-hifi {input} {params.genome_size_flag} {Genome_size} \\
            --out-dir {params.rname}/{params.id} {params.asm_coverage_flag} {Coverage}
        mv /lscratch/$SLURM_JOBID/{params.rname}/{params.id} {params.dir}
        cd {params.dir}/{params.id}
        mv assembly.fasta {output}
        """

# rule canu_assembly:
#     input:
#         fastq_file = lambda w: join(workpath,"reads/{w.samples}.fastq") \
#         if ext[w.samples]=="bam" else join(rawdata_dir, "{w.samples}.fastq")
#     output:
#         FA=join(workpath,"canu_assembly/{samples}.contigs.fasta")
#     params:
#         rname="canu_assembly",
#         dir=directory(join(workpath,"canu_assembly")),
#         tag="{samples}",
#         canu="canu/2.0"
#     threads: 32
#     shell:
#         """
#         module load {params.canu}
#         mkdir -p {params.dir}
#         canu -p {params.tag} -d {params.dir} -fast genomeSize={Genome_size} minThreads={threads} maxThreads={threads} maxMemory=100 stopOnLowCoverage=0 useGrid=false -pacbio-raw {input}
#         """

rule hifiasm:
    input:
        fastq = lambda w: join(workpath, "reads", w.samples+".fastq.gz") if ext[w.samples]=="bam" \
        else \
        join(workpath, w.samples+".fastq.gz"),
    output:
        GFA=join(workpath,"hifiasm_assembly/{samples}.bp.p_ctg.gfa"),
        FA=join(workpath,"hifiasm_assembly/{samples}.hifiasm.fasta"),
    params:
        rname="hifiasm",
        dir=join(workpath,"hifiasm_assembly"),
        out="{samples}",
    threads: int(allocated("threads", "hifiasm", cluster)),
    shell:
        """
        mkdir -p {params.dir}
        module load hifiasm/0.19.8
        hifiasm \\
            -o {params.dir}/{params.out} \\
            -t {threads} \\
            -f0 {input.fastq}
        awk '/^S/{{print ">"$2;print $3}}' \\
            {output.GFA} \\
        > {output.FA}
        """

rule gather_assemblies:
    input:
        A1 = join(workpath,"{assemblers}_assembly/{samples}.{assemblers}.fasta")
    output:
        A1=join(workpath,"all-assemblies/{samples}.{assemblers}.fasta")
    params:
        rname = "gather_assemblies",
        dir=join(workpath, "all-assemblies"),
    threads: int(allocated("threads", "gather_assemblies", cluster)),
    shell:
        """
        mkdir -p {params.dir}
        cp {input.A1} {output.A1}
        sed -i 's/\//_/g' {output.A1}
        """

# rule minimap2_overlaps:
#     input:
#         A1=join(workpath, "all-assemblies/{samples}.{assemblers}.fasta"),
#     output:
#         A1=join(workpath,"minimap2_overlaps/{samples}.{assemblers}-contig-overlap.paf")
#     params:
#         rname="minimap2_overlaps",
#         raw=join(workpath, "reads/{samples}.fasta"),
#         ovlp=join(workpath,"minimap2_overlaps/{samples}.read-read-overlap.paf"),
#         dir=join(workpath,"minimap2_overlaps")
#     threads: 32
#     shell:
#         """
#         module load minimap2
#         mkdir -p {params.dir}
#         minimap2 -t {threads} -x ava-pb {params.raw} {params.raw} > {params.ovlp}
#         minimap2 -t {threads} -x ava-pb {params.raw} {input.A1} > {output.A1}
#         """

rule stats_quast:
    input:
        asm=expand(join(workpath,"all-assemblies/{samples}.{assemblers}.fasta"), samples=SAMPLE, assemblers=ASSEMBLER),
    output:
        ST=join(workpath,"sample-quast/report.html"),
    params:
        rname="stats_quast",
        batch='--cpus-per-task=72 --mem=100g --time=10:00:00',
        dir=directory("sample-quast")
    threads: int(allocated("threads", "stats_quast", cluster)),
    shell:
        """
        module unload python
        module load quast
        module load circos/0.69-9
        quast.py \\
            -o {params.dir} \\
            -t {threads} \\
            --circos \\
            -L {input.asm}
        """


rule stats_busco:
    input:
        asm=join(workpath, "all-assemblies/{samples}.{assemblers}.fasta"),
    output:
        ST=join(workpath,"stats_busco","{samples}.{assemblers}", "short_summary.specific."+Lineage_name+".{samples}.{assemblers}.txt"),
    params:
        rname="stats_busco",
        dir=directory(join(workpath, "stats_busco")), 
        folder="{samples}.{assemblers}",
        odb10_path = odb10_refs_path,
        link = busco_link,
        s = "{samples}",
        Lineage_name = Lineage_name,
        Lineage_path = Lineage_path,
    threads: int(allocated("threads", "stats_busco", cluster)),
    shell:
        """
        module load busco
        mkdir -p {params.dir}
        cd {params.dir}
        if [ ! -d "{params.Lineage_path}" ] && [ "{params.Lineage_name}" != "" ]; then
            echo "downloading busco lineage to current working dir"
            wget {params.link} -O busco_lineage.tar.gz; 
            tar -vxzf busco_lineage.tar.gz; rm -f busco_lineage.tar.gz;
            busco --offline \\
                -m genome \\
                -l {params.dir}/{params.Lineage_name} \\
                -c {threads} \\
                -i {input.asm} \\
                -f -o {params.folder}
        elif [ "{params.Lineage_name}" == "" ]; then
            echo "running busco without input database"
            busco \\
                --offline \\
                -m genome \\
                -c {threads} \\
                -i {input.asm} \\
                -f -o {params.folder}
        else
            echo "running busco with input database"
            busco \\
                --offline \\
                -m genome \\
                -l {params.Lineage_path} \\
                -c {threads} \\
                -i {input.asm} \\
                -f -o {params.folder}
        fi
        """


rule busco_summaries:
    input:
        expand(join(workpath,"stats_busco","{samples}.{assemblers}", "short_summary.specific."+Lineage_name+".{samples}.{assemblers}.txt"), assemblers=ASSEMBLER, Lineage_name=Lineage_name, samples=SAMPLE),
    output:
        join(workpath,"busco-summaries/busco_figure.png"),
    params:
        rname="busco_summaries",
        dir=directory(join(workpath, "busco-summaries")),
    threads: int(allocated("threads", "busco_summaries", cluster)),
    shell:
        """
        module load busco
        mkdir -p {params.dir}
        cp {input} {params.dir}
        generate_plot.py \\
            -rt specific \\
            --working_directory {params.dir}
        """
